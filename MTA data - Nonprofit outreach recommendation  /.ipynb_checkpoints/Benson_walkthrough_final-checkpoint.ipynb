{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First things first - Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages - shorthand will be referred to from this point on. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "#import googlemaps \n",
    "import re as re\n",
    "import seaborn as sns\n",
    "import locale\n",
    "from locale import atof\n",
    "import math as math\n",
    "import dateutil\n",
    "from dateutil import parser\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# enables inline plots, without it plots don't show up in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set display parameters\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows',50)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy part 1: Which stations are near in the highest income areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging income per zipcode with MTA turnstyle locations \n",
    "* Read median data per zip code from:\n",
    "    * ACS csv\n",
    "    * Stations w/ zip codes from other notebook in folder (provides Google geolocation API)\n",
    "    \n",
    "Merge 2 data frames and drop data from New Jersey (7 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: new data frame  \"acs\" - data frame containing income data by zipcode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs = pd.read_csv('ACS_zip2.csv') #Reading ACS csv file\n",
    "acs.rename(columns={'Zip':'zipcode'}, inplace=True) #Renaming column name in order to merge. \n",
    "locale.setlocale(locale.LC_NUMERIC, '')  #Correcting formatting of number string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs.head() #View the top few rows just to check out what it's doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs['Median'] = acs[['Median']].applymap(atof); #Correcting median column formatting.\n",
    "acs['Median_adjusted'] = acs[['Median_adjusted']].applymap(atof); #Correcting median_adjusted column formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs.info() #Getting info on the data types in the acs data frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"stations\" with subway stations paired with their zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in station zipcodes data frame from google api calls in Benson_geolocation_final\n",
    "stations = pd.read_csv('zipcode_df.csv')\n",
    "stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations.head(5) #View the top few rows jsut to checkout how it's working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"merged\" is  stations data frame merged with acs data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating merged data frame, and merging \"stations\" and \"acs\". \n",
    "merged = pd.merge(stations,acs,on='zipcode', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isnull().sum() #Checking which columns have \"null\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 7 stations that don't have data and are in New Jersey - from 366 rows to 359\n",
    "merged = merged[merged['Median'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged) #Checking how many rows (the length) of the data frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge station location/income with turnstile data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: First instance of \"df\" data frame containing MTA turnstyle information. Will now be merged with \"merged\" data frame to give income information for each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NYC turntable for the month of march, from march 3rd to march 30th (4weeks)\n",
    "#df = pd.read_csv(\"NYCT180310.csv\")\n",
    "path =r'/Users/vicky/Documents/GitHub/Metis/MTA data - Nonprofit outreach recommendation' \n",
    "# use the path where your csv files are located. Mine is quite long...\n",
    "all_files = glob.glob(os.path.join(path, \"NYCT*.csv\")) \n",
    "all_files\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files)) #Combining the seperate csvs into one. \n",
    "df.columns = df.columns.str.strip() #Striping rogue spaces from column names (will be easier to work with)\n",
    "df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"df_m\" is merge \"df\" and \"merged\" data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.merge(df,merged,on='STATION') #Merging data frames on column \"STATION\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"df_mr\" is cleaned of all instances with zeros in the \"ENTRIES\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mr = df_m[df_m.ENTRIES != 0] #Cleanign data by removing entries with \"0\".\n",
    "len(df_mr[df_mr[\"ENTRIES\"] == 0]) #Checking how many zeros we're removing. \n",
    "print(\"removed\", len(df_m) - len(df_mr), \"entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_mr.STATION.unique())) #Checking how many unique station names are in our data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mr.head() #View the top few rows just to check out what it's doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns with important information: Date-time and day of week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the datetime for each entry and adding it as the 7th row (6th index).\n",
    "date_time = pd.to_datetime(df_mr.DATE + \" \" + df_mr.TIME, format=\"%m/%d/%Y %H:%M:%S\") #Evaluating datetime\n",
    "df_mr.insert(loc=6, column='DATE_TIME', value=date_time) #Inserting it as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the datetime date and adding it as the 8th row (7th index).\n",
    "date_date = pd.to_datetime(df_mr.DATE, format=\"%m/%d/%Y\") #Evaluating date\n",
    "df_mr.insert(loc=7, column='DATE_DATE', value=date_date) #Inserting it as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the datetime time and add it as the 10th row (9th index). \n",
    "time = df_mr.DATE_TIME.dt.time #Evaluating time\n",
    "df_mr.insert(loc=9, column = \"TIME_TIME\", value=time) #Inserting it as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the day of week as the column. \n",
    "day_of_week = df_mr.DATE_TIME.dt.weekday #Evaluating day of week. Method returns a number 0-6 depending on which day of the week. \n",
    "df_mr.insert(loc=5, column='day_of_week', value=day_of_week) #Inserting it as a column\n",
    "df_mr.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mr.head() #View the top few rows just to check out what it's doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get aggregate weekday entries per station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame df_wd contains entries of stations and ridership during week days only (no weekends). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd = df_mr[df_mr['day_of_week'] < 5] #Adding only weekdays to new dataframe by excluding identified weekend days. \n",
    "#Now there is only Mon - Fri data (0 - 4)\n",
    "df_wd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame gb_enter groups entries into \"turnstyles\" per day by grouping the station name, the line name, and other identifiers unique to each station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of entries per day for each station by finding the difference between the min and max turnstyle counts. \n",
    "#Helps eliminate errors with weird turnstile jump\n",
    "gb_enter = df_wd.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\", \"DATE\"]).ENTRIES.agg([\"min\", \"max\"]) \n",
    "#Grouping, finding the min and max. \n",
    "#Creating a new columb \"dif\" that finds the difference between them (and the total ridership for that day.)\n",
    "gb_enter[\"dif\"] = gb_enter[\"max\"] - gb_enter[\"min\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"gb_enter_r\" is cleaned - removed unlikely entries (over 15,000 entries per day). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided to set a cutoff of 15,000. \n",
    "#Anything higher seems suspicious, and is likely to either represent a broken turn style, or a turnstyle who's counter hs \"reset\". \n",
    "gb_enter_r = gb_enter[gb_enter.dif < 15000] #Setting the cutoff. \n",
    "sns.boxplot(gb_enter_r.dif);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_enter_r = gb_enter_r.reset_index()\n",
    "gb_enter_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"gb_enter_f\" has entries summed across all days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summed entries accross all days and turnstiles for a station to find the aggregate traffic at that station & line.\n",
    "gb_enter_f = gb_enter_r.groupby([\"STATION\",\"LINENAME\"]).agg(\"sum\").sort_values(\"dif\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_enter_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_enter_f = gb_enter_f.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"gb_enter_final\" contains only Station, linename and total entries information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only the columns we need\n",
    "gb_enter_final = gb_enter_f[['STATION','LINENAME','dif']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the same thing as before, this time counting \"exits\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat entry steps to get aggregate counts for station over the time period\n",
    "gb_exit = df_wd.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\", \"DATE\"]).EXITS.agg([\"min\", \"max\"])\n",
    "gb_exit[\"exit_dif\"] = gb_exit[\"max\"] - gb_exit[\"min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toss out diffs > 1500 again\n",
    "gb_exit_r = gb_exit[gb_exit.exit_dif < 15000]\n",
    "sns.boxplot(gb_exit_r.exit_dif);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_exit_r = gb_exit_r.reset_index()\n",
    "gb_exit_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_exit_f = gb_exit_r.groupby([\"STATION\",\"LINENAME\"]).agg(\"sum\").sort_values(\"exit_dif\", ascending=False)\n",
    "gb_exit_f = gb_exit_f.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_exit_final = gb_exit_f[['STATION','LINENAME','exit_dif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_exit_final.sort_values(by=['STATION','LINENAME']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join together relevant entries, exits and income per stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frames... \n",
    "#### \"enter_exit_merge\" with data about entry totals, exit totals, and income per zipcode info. \n",
    "#### \"traffic_income_merge\" merging enter_exit information with income/zipcode data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join entries and exits\n",
    "enter_exit_merge = pd.merge(gb_enter_final,gb_exit_final,on=['STATION','LINENAME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_exit_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join income\n",
    "traffic_income_merge = pd.merge(enter_exit_merge,merged,on='STATION')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_traffic = traffic_income_merge.dif + traffic_income_merge.exit_dif\n",
    "#Summing the entry and exit totals, and creating a new column \"total_traffic\". \n",
    "traffic_income_merge.insert(loc=2, column='total_traffic', value=total_traffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traffic_income_merge.sort_values(\"total_traffic\", ascending=False).head() #Sorting to see which station has highest traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " traffic_income_merge.total_traffic.std() #Finding the standard deviation of the total traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_income_merge.sort_values(\"total_traffic\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_income_merge #Viewing the sorted results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate High Income Stations with high traffic for selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare threshold for demographic\n",
    "min_income = 100000\n",
    "min_traffic = 600000\n",
    "\n",
    "\n",
    "#Graph income vs traffic for stations for selection\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "sns.regplot(x=\"total_traffic\", y=\"Median_adjusted\", fit_reg = False,data=traffic_income_merge)\n",
    "plt.axhline(min_income, color='grey')\n",
    "plt.axvline(min_traffic, color='grey')\n",
    "plt.ylabel('Median Income ($)', fontsize=16)\n",
    "plt.xlabel('Total Weekday Traffic (March, 2018)', fontsize=16)\n",
    "plt.title('Station Weekday Traffic vs Income', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the number of stations in selected area\n",
    "len(traffic_income_merge[(traffic_income_merge['total_traffic'] >= min_traffic) & (traffic_income_merge['Median_adjusted'] >=min_income)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"top_income_stops\" contains data frame with only selected high traffic/high income stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_income_stops = traffic_income_merge[(traffic_income_merge['total_traffic'] >= min_traffic) & (traffic_income_merge['Median_adjusted'] >=min_income)].sort_values(\"total_traffic\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_income_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yay! we've found the stations with the most traffic and highest income! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy part 2: Stations near technical companies/HS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data set \"techies\" is the lsit of stations near technical areas of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techies = pd.read_csv('stations_near_tech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy part 3: The best time of day?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a column for time differences between exits and entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mr.head()\n",
    "#copy table for work\n",
    "df_mr_daily = df_mr\n",
    "df_mr_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: sorted_dr_mr_daytime_entry is sorted data grouped by each turnstyle and the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_mr_daytime_entry = df_mr_daily.sort_values(by=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\", \"DATE_TIME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_mr_daytime_entry.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Entries Hourly diff\n",
    "#group by turnstile identifiers, and get the difference between the time points & one before within each turnstile/date\n",
    "#will result in NANs where there is no vlaue preceeding group_by \n",
    "\n",
    "sorted_df_mr_daytime_entry['entry_diff'] = sorted_df_mr_daytime_entry.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\",'DATE_DATE'])['ENTRIES'].transform(lambda x:x.diff())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Exits Hourly diff\n",
    "sorted_df_mr_daytime_entry['exits_diff'] = sorted_df_mr_daytime_entry.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"LINENAME\",'DATE_DATE'])['EXITS'].transform(lambda x:x.diff())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_df_mr_daytime_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONly including entry counts that are greater than 0. \n",
    "sorted_df_mr_daytime_entry = sorted_df_mr_daytime_entry[(sorted_df_mr_daytime_entry[\"exits_diff\"] > 0) | (sorted_df_mr_daytime_entry[\"entry_diff\"] > 0)]\n",
    "len(sorted_df_mr_daytime_entry) \n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: New data frame \"sorted_df_mr_daytime_wd\" only includes weekdays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove weekends from this dataframe\n",
    "sorted_df_mr_daytime_wd = sorted_df_mr_daytime_entry[sorted_df_mr_daytime_entry['day_of_week'] < 5]\n",
    "#df_mr_daily_wd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_mr_daytime_wd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find average ridership entry for each time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by station, linename, and time to get the median traffic for that time point and station\n",
    "#e.g. The median number of people entering the 1st AV L stop at 8AM (over the month) was 104.5\n",
    "\n",
    "entries_diff = sorted_df_mr_daytime_wd.groupby(['STATION', 'LINENAME' , 'TIME_TIME'],as_index = False)['entry_diff'].agg(\"median\")\n",
    "entries_diff.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat with exits\n",
    "exits_diff = sorted_df_mr_daytime_wd.groupby(['STATION', 'LINENAME' , 'TIME_TIME'], as_index = False)['exits_diff'].agg(\"median\")\n",
    "exits_diff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge aggregated entries and exits\n",
    "total_daily_time_traffic = pd.merge(exits_diff,entries_diff,on=['STATION','LINENAME','TIME_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_daily_time_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 8}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library for keys\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for 'hour' for aggregate AM/PM analysis\n",
    "def hr_func(ts):\n",
    "    return ts.hour\n",
    "total_daily_time_traffic['HOUR'] = total_daily_time_traffic['TIME_TIME'].apply(hr_func)\n",
    "total_daily_time_traffic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AM/PM patterns for Tech Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge tech stations with hourly traffic aggregate\n",
    "techie_traffic = pd.merge(techies,total_daily_time_traffic, on ='STATION' )\n",
    "techie_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_morning = techie_traffic[(techie_traffic['HOUR'] < 12) & (techie_traffic['HOUR'] > 6)]\n",
    "tech_morning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum median traffic over morning hours\n",
    "tech_morning_sum = tech_morning.groupby(['STATION']).sum()\n",
    "tech_morning_sum = tech_morning_sum.reset_index().sort_values('exits_diff').reset_index()\n",
    "tech_morning_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top to graph\n",
    "techie_morning_to_graph = tech_morning_sum.iloc[13:21]\n",
    "techie_morning_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(techie_morning_to_graph['STATION'],techie_morning_to_graph['exits_diff'], color = '#1A62A5')\n",
    "plt.ylabel('Station', fontsize=14)\n",
    "plt.xlabel('Total Morning Traffic', fontsize=14)\n",
    "plt.title('Tech Hubs: AM Exits Traffic per Station', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_evening = techie_traffic[(techie_traffic['HOUR'] > 12)]\n",
    "tech_evening.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_evening_sum = tech_evening.groupby(['STATION']).sum()\n",
    "tech_evening_sum = tech_evening_sum.reset_index().sort_values('exits_diff').reset_index()\n",
    "tech_evening_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techie_evening_to_graph = tech_evening_median.iloc[13:21]\n",
    "techie_evening_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(techie_evening_to_graph['STATION'],techie_evening_to_graph['exits_diff'],color = 'orange')\n",
    "plt.ylabel('Station', fontsize=14)\n",
    "plt.xlabel('Total Evening Traffic', fontsize=14)\n",
    "plt.title('Tech Hubs: PM Entries per Station', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AM/PM patterns for High Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_inc_traf = pd.merge(total_daily_time_traffic,top_income_stops, on = ['STATION','LINENAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning = high_inc_traf[(high_inc_traf['HOUR'] < 12) & (high_inc_traf['HOUR'] > 6)]\n",
    "df_morning;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evening = high_inc_traf[(high_inc_traf['HOUR'] > 4)]\n",
    "df_evening.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning_sum = df_morning.groupby(['STATION']).sum()\n",
    "df_morning_sum = df_morning_sum.reset_index().sort_values('entry_diff').reset_index()\n",
    "df_morning_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evening_sum = df_evening.groupby(['STATION']).sum()\n",
    "df_evening_sum = df_evening_sum.reset_index().sort_values('exits_diff').reset_index()\n",
    "df_evening_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_to_graph = df_evening_sum.iloc[18:28,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_to_graph = evening_to_graph.reset_index().sort_values('exits_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_to_graph = df_morning_sum.iloc[18:28,:]\n",
    "morning_to_graph = morning_to_graph.sort_values('entry_diff')\n",
    "morning_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(evening_to_graph['STATION'],evening_to_graph['exits_diff'],color = '#1A62A5')\n",
    "plt.ylabel('Station', fontsize=14)\n",
    "plt.xlabel('Total Evening Traffic', fontsize=14)\n",
    "plt.title('High Income: PM Exit Traffic per Station', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(morning_to_graph['STATION'],morning_to_graph['entry_diff'],color = 'orange')\n",
    "plt.ylabel('Station', fontsize=16)\n",
    "plt.xlabel('Total Morning Traffic', fontsize=16)\n",
    "plt.title('High Income: AM Entries Traffic per Station', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrap plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print (\"Current size:\", fig_size)\n",
    "\n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the total traffic over time for all high income stations\n",
    "#note that this was original written as a for loop to make plots for all stations\n",
    "#should be cleaned up\n",
    "\n",
    "plt.close(fig)\n",
    "name_list = top_income_stops[\"STATION\"].unique()\n",
    "for i in range(3,4):\n",
    "    name = name_list[i]\n",
    "    #print(name)\n",
    "    station = total_daily_time_traffic[total_daily_time_traffic['STATION']==name]\n",
    "    #print(station)\n",
    "    #plt.subplot(29, 1, (i+1))\n",
    "    plt.plot(station['TIME_TIME'], station['entry_diff'], 'orange', station['TIME_TIME'], station['exits_diff'], '#1A62A5')\n",
    "    plt.ylabel('Median Traffic', fontsize=14)\n",
    "    plt.xlabel('Time of Day', fontsize=14)\n",
    "    key_entry = mpatches.Patch(color='orange', label='Entries')\n",
    "    key_exit = mpatches.Patch(color='#1A62A5', label='Exits')\n",
    "    plt.legend(handles=[key_entry,key_exit])\n",
    "    plt.title('High Income Stations: Daily Traffic', fontsize=20)\n",
    "    plt.figure(figsize=(150,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot to make time points for a single station over time\n",
    "\n",
    "# station = total_daily_time_traffic[total_daily_time_traffic['STATION']=='66 ST-LINCOLN']\n",
    "# #print(station)\n",
    "# #plt.subplot(29, 1, (i+1))\n",
    "# plt.plot(station['TIME_TIME'], station['entry_diff'], 'ro', station['TIME_TIME'], station['exits_diff'], 'go')\n",
    "# plt.ylabel('Median Traffic', fontsize=14)\n",
    "# plt.xlabel('Time of Day', fontsize=14)\n",
    "# key_entry = mpatches.Patch(color='red', label='Entries')\n",
    "# key_exit = mpatches.Patch(color='green', label='Exits')\n",
    "# plt.legend(handles=[key_entry,key_exit])\n",
    "# plt.figure(figsize=(10,15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
